{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP Transco assignment\n",
    "\n",
    "Given an audio conversation between two people you need to:\n",
    "\n",
    "* Produce a concise summary encapsulating the essential points of the conversation.\n",
    "* Rate the overall sentiment of the dialogue on a scale from 1 to 10,  with 1 indicating a highly negative sentiment and 10 denoting a highly positive sentiment.\n",
    "* Extract key emotions in call with their score for each ranging from 1 to 10 with 1 indicating a highly negative sentiment and 10 denoting a highly positive sentiment.\n",
    "* Extract Appointment time to Delivery from the dialogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pprint as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility funcs\n",
    "\n",
    "* Using a single function for completions, only manipulating the system prompt.\n",
    "* Need to set your own OPENAI_API_KEY env variable.\n",
    "* No error handling or reproducibility efforts as this is only a mock-up with a single data entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a global openai client instance\n",
    "client = OpenAI()\n",
    "\n",
    "# generate the transcript\n",
    "def get_transcript(audio_file_name):\n",
    "  audio_file = open(audio_file_name, \"rb\")\n",
    "  transcript = client.audio.transcriptions.create(\n",
    "    file=audio_file,\n",
    "    model=\"whisper-1\",\n",
    "    response_format=\"text\",\n",
    "    # no need for the timestamps in this simple case\n",
    "  #   timestamp_granularities=[\"word\"]\n",
    "  )\n",
    "  return transcript\n",
    "\n",
    "\n",
    "# a generic function to get the gpt completion\n",
    "def get_completion(model_name, temperature, max_tokens, system_prompt, input):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": input\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Generate a transcript of the call.\n",
    "\n",
    "* Use Whisper API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The transcript: \n",
      "(\"Hey, Fidel, I'm sorry, this is Juan. Hey, I'm done with the truck. Okay, \"\n",
      " 'perfect, perfect. What time is my truck going to kick in tomorrow? Let me '\n",
      " 'see real quick. For tomorrow it says open window, actually. Let me double '\n",
      " 'check that real quick, Fidel. I have an 8 a.m. appointment time for the '\n",
      " 'delivery. On Wednesday? On Wednesday, yes, sir. Alright. Yeah, yeah. But '\n",
      " \"it's a 24-7 facility, so if you have any trouble on the route, just give me \"\n",
      " \"a call so we can fix it, okay? Yeah, I'm not leaving until tomorrow. I'm out \"\n",
      " \"of time, so I just use PC out here? No, no, no, it's fine, it's fine. Are \"\n",
      " \"you at HQ, right? Yeah, I'm out of time, so... No, it's fine, you can sit \"\n",
      " 'down at headquarters. So I roll with YARMUV? Do I use YARMUV? Oh, yeah, '\n",
      " \"YARMUV, it's okay, it's fine. Okay, yeah, and you can also take the 15 \"\n",
      " \"minutes for the post-trip. It won't count like a violation, so you can take \"\n",
      " 'the 15 minutes for the post-trip. Oh, I can use it with the YARMUV? Yeah, '\n",
      " 'yeah, yeah. Once you use the YARMUV and park, you can put yourself on '\n",
      " 'non-duty for the post-trip. Post-trip? Yes, sir. It is get out of YARMUV to '\n",
      " 'on-duty? Exactly, yeah. Just before you end with the YARMUV, put yourself on '\n",
      " 'duty, make the post-trip, and then sleep-prepared or off-duty. All right, '\n",
      " 'sleep-prepared. Yeah. All right, then. All right, thank you. Okay, bye-bye. '\n",
      " 'All right. Bye.\\n')\n"
     ]
    }
   ],
   "source": [
    "# try out the basic transcription first, whisper api\n",
    "audio_file_name = \"aud-20240305025406001766-5f28b652ac8760c054204aa095bc31e3-C862.wav\"\n",
    "\n",
    "transcript = get_transcript(audio_file_name)\n",
    "\n",
    "\n",
    "print(\"The transcript: \")\n",
    "# pprint to make it more readable in the notebook\n",
    "pp.pprint(transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Produce a concise summary encapsulating the essential points of the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consice summary: \n",
      "- Juan informs Fidel that he has finished with the truck.\n",
      "- Juan inquires about his next schedule, and Fidel confirms an 8 a.m. delivery appointment on Wednesday.\n",
      "- Fidel mentions the delivery location is a 24-7 facility and offers assistance if Juan encounters any issues on the route.\n",
      "- Juan states he won't leave until tomorrow due to being out of driving time and asks if he should use Personal Conveyance (PC) to move the truck.\n",
      "- Fidel advises Juan to stay at headquarters instead of using PC and confirms it's fine to use Yard Move (YARMUV) for necessary movements.\n",
      "- Fidel allows Juan to take 15 minutes for a post-trip inspection without it counting as a violation.\n",
      "- Juan is instructed to switch from YARMUV to on-duty for the post-trip inspection, then to sleeper berth or off-duty status.\n"
     ]
    }
   ],
   "source": [
    "# let's go with gpt4-turbo-preview\n",
    "model_name = \"gpt-4-turbo-preview\"\n",
    "# temperature or top_p where the model considers the results of the tokens with top_p probability mass.\n",
    "temperature = 0\n",
    "max_tokens = 1000\n",
    "system_prompt = \"\"\"\n",
    "    You are a helpful assistant for a logistics company. Your task is to produce a \n",
    "    concise summary of the conversation between a truck driver and his manager in \n",
    "    the transcribed text encapsulating the essential points. Write down the main \n",
    "    bullet points summarizing the conversation. Use only the context provided, don't use abbreviations.\n",
    "    \"\"\"\n",
    "\n",
    "summary = get_completion(model_name, temperature, max_tokens, system_prompt, transcript)\n",
    "\n",
    "print(\"Consice summary: \")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Rate the overall sentiment of the dialogue on a scale from 1 to 10,  with 1 indicating a highly negative sentiment and 10 denoting a highly positive sentiment.\n",
    "\n",
    "* Process the original transcript as the sentiment needs to be derived from the complete conversation, not the summary.\n",
    "* One could also consider sentiment over time (both during the conversation and how the sentiment changes between different conversations in time).\n",
    "* Only the overall sentiment is needed, not individual sentiments from each person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 0\n",
    "# only need a single token in the completion\n",
    "max_tokens = 1\n",
    "model_name = \"gpt-4-turbo-preview\"\n",
    "system_prompt = \"\"\"\n",
    "    You are a helpful sentiment analyzer assistant. Your task is to determine what is the\n",
    "    sentiment conveyed by the text. Rate the overall sentiment of the dialogue on a scale \n",
    "    from 1 to 10, with 1 indicating a highly negative sentiment and 10 denoting a highly \n",
    "    positive sentiment. Provide only a sentiment rating in the reply.\n",
    "    \"\"\"\n",
    "\n",
    "sentiment = get_completion(model_name, temperature, max_tokens, system_prompt, transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall sentiment: \n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall sentiment: \")\n",
    "print(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract key emotions in call with their score for each ranging from 1 to 10 with 1 indicating a highly negative sentiment and 10 denoting a highly positive sentiment.\n",
    "\n",
    "* Possibly need to figure out what are the possible/relevant key emotions first. But for now just go with what gpt provides.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens=1000\n",
    "system_prompt = \"\"\"\n",
    "    You are an advanced sentiment and emotion analyzer assistant. Your task is\n",
    "    to determine what are the strongest positive and negative emotions in the provided conversation text. Extract from \n",
    "    two to eight key emotions in the conversation and rate each of those emotions on a scale \n",
    "    from 1 to 10, with 1 indicating a highly negative sentiment and 10 denoting a highly positive\n",
    "    sentiment. Return a table with the name of the emotion and its rating in each row.\n",
    "    \"\"\"\n",
    "\n",
    "key_emotions = get_completion(model_name, temperature, max_tokens, system_prompt, transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key emotions: \n",
      "| Emotion         | Rating |\n",
      "|-----------------|--------|\n",
      "| Cooperation     | 9      |\n",
      "| Reassurance     | 8      |\n",
      "| Understanding   | 8      |\n",
      "| Patience        | 7      |\n",
      "| Concern         | 6      |\n",
      "| Relief          | 7      |\n"
     ]
    }
   ],
   "source": [
    "print(\"Key emotions: \")\n",
    "print(key_emotions)\n",
    "# it seems that the rating of emotions is not consistent over multiple runs.\n",
    "# also, it would be useful to provide a list of relevant emotions to the model for more consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extract Appointment time to Delivery from the dialogue.\n",
    "\n",
    "* Again, here we use the original transcript, not the summary.\n",
    "* As there are no further details, return the delivery time in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "    You are a helpful assistant for a logistics company. Your task is\n",
    "    to analyze the provided input conversation and extract the appointment \n",
    "    time to delivery from the conversation. Return the exact extracted delivery \n",
    "    appointment time in a brief summary sentence.\n",
    "    \"\"\"\n",
    "\n",
    "delivery_time = get_completion(model_name, temperature, max_tokens, system_prompt, transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delivery time: \n",
      "The delivery appointment time is at 8 a.m. on Wednesday.\n"
     ]
    }
   ],
   "source": [
    "print(\"Delivery time: \")\n",
    "print(delivery_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-conda-env-kernel",
   "language": "python",
   "name": "my-conda-env-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
